<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yudong Guo</title>

  <meta name="author" content="Yudong Guo">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Yudong Guo</name>
                  </p>
                  <p>I am an assistant professor at <a
                    href="http://en.ustc.edu.cn/">University of Science and Technology of China (USTC)</a>. I got my Ph.D. degree from USTC in 2021, supervised by <a
                      href="http://staff.ustc.edu.cn/~juyong/">Prof. Juyong Zhang</a>. Before that, I received bachelor
                    degree in Statistics in 2015 from USTC. From fall
                    2016 to spring 2017, I was a research assistant in the MultiMedia Lab at Nanyang Technological
                    University under supervision of <a href="https://jianfei-cai.github.io/">Prof. Jianfei Cai</a> and
                    <a href="https://personal.ntu.edu.sg/asjmzheng/">Prof. Jianmin Zheng</a>. My
                    research interests include 3D vision and digital human.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:yudong@ustc.edu.cn">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=cxF_-i4AAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/YudongGuo/">Github</a>
                  </p>
                </td>
                <td style="padding: 10% 2% 10% 2%;width:40%;max-width:40%">
                  <img src="images/Yudong.jpg" style="float:center" width="70%" alt="photo">
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/osot.gif' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ustc3dv.github.io/OneShotOneTalk/">
                    <papertitle>
                      One Shot, One Talk: Whole-body Talking Avatar from a Single Image</papertitle>
                  </a>
                  <br>
                  <a href="https://xiangjun-xj.github.io/">Jun Xiang</a>, <strong>Yudong Guo</strong>, Leipeng Hu, Boyang Guo, <a href="https://paulyuanmath.github.io/">Yancheng Yuan</a>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
                  <br>
                  <em>Arxiv</em>, 2024
                  <br>
                  <a href="https://ustc3dv.github.io/OneShotOneTalk/">project page</a> /
                  <a href="https://yudongguo.github.io/">paper (comming soon)</a> /
                  <a href="https://yudongguo.github.io/">code (comming soon)</a> 
                  <p>
                    We adopt a 3DGS-Mesh coupled representation with pre-trained human video diffusion models for one-shot vivid talking avatars.
                  </p>
                </td>
              </tr>
              
              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/pica.gif' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ustc3dv.github.io/PICA/">
                    <papertitle>
                      PICA: Physics-Integrated Clothed Avatar</papertitle>
                  </a>
                  <br>
                  Bo Peng, Yunfan Tao, Haoyu Zhan, <strong>Yudong Guo</strong>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
                  <br>
                  <em>Arxiv</em>, 2024
                  <br>
                  <a href="https://ustc3dv.github.io/PICA/">project page</a> /
                  <a href="https://arxiv.org/abs/2407.05324">paper</a> /
                  <a href="https://yudongguo.github.io/">code (comming soon)</a> 
                  <p>
                    We integrate a neural physics simulation engine with the 3DGS avatar for realistic clothed body animation.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/PortraitGen.gif' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ustc3dv.github.io/PortraitGen/">
                    <papertitle>
                      Portrait Video Editing Empowered by Multimodal Generative Priors</papertitle>
                  </a>
                  <br>
                  <a href="https://xuanghahahaha.github.io/">Xuan Gao</a>, Haiyao Xiao, Chenglai Zhong, Shimin Hu, <strong>Yudong Guo</strong>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
                  <br>
                  <em>SIGGRAPH Asia Conference Proceedings</em>, 2024
                  <br>
                  <a href="https://ustc3dv.github.io/PortraitGen/">project page</a> /
                  <a href="https://arxiv.org/abs/2409.13591">paper</a> /
                  <a href="https://github.com/USTC3DV/PortraitGen-code">code</a> 
                  <p>
                    We combine FlashAvatar with multimodal generative models to achieve consistent portrait video editing.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/flashavatar.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ustc3dv.github.io/FlashAvatar/">
                    <papertitle>FlashAvatar: High-fidelity Head Avatar with Efficient Gaussian Embedding</papertitle>
                  </a>
                  <br>
                  Jun Xiang, Xuan Gao, <strong>Yudong Guo</strong>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024
                  <br>
                  <a href="https://ustc3dv.github.io/FlashAvatar/">project page</a> /
                  <a href="https://arxiv.org/abs/2312.02214">paper</a> /
                  <a href="https://github.com/USTC3DV/FlashAvatar-code">code</a> 
                  <p>We attach 3DGS on mesh UV space to achieve 300FPS head avatar rendering.</p>
                </td>
              </tr>

              <tr onmouseout="total_stop()" onmouseover="total_start()">
                <td style="vertical-align:middle">
                  <div class="one">
                    <div class="two" id='total_image'><video  width="200"  muted autoplay loop>
                    <source src="images/totalselfscan.mp4" type="video/mp4" width="200">
                    Your browser does not support the video tag.
                    </video></div>
                    <img src='images/totalselfscan.jpg' width="200">
                  </div>
                  <script type="text/javascript">
                    function total_start() {
                      document.getElementById('total_image').style.opacity = "1";
                    }
    
                    function total_stop() {
                      document.getElementById('total_image').style.opacity = "0";
                    }
                    total_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://zju3dv.github.io/TotalSelfScan/">
                    <papertitle>TotalSelfScan: Learning Full-body Avatars from Self-Portrait Videos of Faces, Hands, and Bodies</papertitle>
                  </a>
                  <br>
                  <a
                  href="https://jtdong.com/">Junting Dong*</a>,
            <a
            href="https://raypine.github.io/">Qi Fang*</a>,
                  <strong>Yudong Guo</strong>,
                  <a
                    href="https://pengsida.net/">Sida Peng</a>,
                    <a
                    href="https://chingswy.github.io/">Qing Shuai</a>,
                    <a
                    href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>,
                    <a
                    href="https://xzhou.me/">Xiaowei Zhou</a>
                  <br>
                  <em>NeurIPS</em>, 2022
                  <br>
                  <a href="https://zju3dv.github.io/TotalSelfScan/">project page</a> /
            <a href="https://openreview.net/pdf?id=lgj33-O1Ely">paper</a> /
            <a href="https://github.com/zju3dv/totalselfscan">code</a> 
                  <p></p>
                </td>
              </tr>


              <tr>
                <td style="vertical-align:middle">
                  <img src='images/nerfblendshape.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ustc3dv.github.io/NeRFBlendShape/">
                    <papertitle>Reconstructing Personalized Semantic Facial NeRF Models From Monocular Video</papertitle>
                  </a>
                  <br>
                  Xuan Gao, Chenglai Zhong, Jun Xiang, <a href="http://hy1995.top/">Yang Hong</a>, <strong>Yudong Guo</strong>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
                  <br>
                  <em>SIGGRAPH Asia (Journal Track) </em>, 2022
                  <br>
                  <a href="https://ustc3dv.github.io/NeRFBlendShape/">project page</a> /
                  <a href="https://arxiv.org/abs/2210.06108">paper</a> /
                  <a href="https://github.com/USTC3DV/NeRFBlendShape-code">code</a> 
                </td>
              </tr>


              <tr>
                <td style="vertical-align:middle">
                  <img src='images/HeadIDR.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2107.04277">
                    <papertitle>Prior-Guided Multi-View 3D Head Reconstruction</papertitle>
                  </a>
                  <br>
                  Xueying Wang, <strong>Yudong Guo</strong>, Zhongqi Yang, <a
                    href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
                  <br>
                  <em>IEEE Transactions on Multimedia (TMM) </em>, 2021
                  <br>
                  <a href="https://arxiv.org/abs/2107.04277">paper</a>
                  <p>We utilize prior-guided implicit neural rendering to reconstruct the 3D head model.</p>
                </td>
              </tr>

              <tr>
                <td style="vertical-align:middle">
                  <img src='images/AD-NeRF.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://yudongguo.github.io/ADNeRF/">
                    <papertitle>AD-NeRF: Audio Driven Neural Radiance Fields for Talking Head Synthesis</papertitle>
                  </a>
                  <br>
                  <strong>Yudong Guo</strong>, Keyu Chen, Sen Liang, <a
                    href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm">Yongjin Liu</a>, <a
                    href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>, <a
                    href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
                  <br>
                  <em>IEEE International Conference on Computer Vision (ICCV) </em>, 2021
                  <br>
                  <a href="https://yudongguo.github.io/ADNeRF/">project page</a> /
                  <a href="https://arxiv.org/abs/2103.11078">paper</a> /
                  <a href="https://github.com/YudongGuo/AD-NeRF">code</a> /
                  <a href="https://www.youtube.com/watch?v=TQO2EBYXLyU">video</a>
                  <p>We address the talking head problem with the aid of dynamic neural radiance fields.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/FaceFromX.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/1808.05323">
                    <papertitle>3D Face From X: Learning Face Shape from Diverse Sources</papertitle>
                  </a>
                  <br>
                  <strong>Yudong Guo</strong>, Lin Cai, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
                  <br>
                  <em>IEEE Transactions on Image Processing (TIP) </em>, 2021
                  <br>
                  <a href="https://arxiv.org/abs/1808.05323">paper</a> /
                  <a href="data/FaceFromX.mp4">video</a>
                  <p>We present a method to jointly learn a 3D face parametric model and 3D face reconstruction from diverse sources.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/FaceCorrection.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Real-Time Face View Correction for Front-Facing Cameras</papertitle>
                  <br>
                  <strong>Yudong Guo</strong>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>, Yihua Chen,
                  <a href="https://github.com/RainbowRui">Hongrui Cai</a>, <a href="http://staff.ustc.edu.cn/~zhuang/">Zhangjin Huang</a>, <a
                    href="http://www.bdeng.me/">Bailin Deng</a>
                  <br>
                  <em>Computational Visual Media </em>, 2021
                  <br>
                  <a href="data/FaceViewCorrection.pdf">paper</a> /
                  <a href="data/FaceViewCorrection.mp4">video</a>
                  <p>Given the video stream from a single camera, we generate a stream that emulates the view from a virtual camera at a designated location.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/StereoPiFU.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>StereoPIFu: Depth Aware Clothed Human Digitization via Stereo Vision</papertitle>
                  <br>
                  <a href="http://hy1995.top/">Yang Hong</a>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong
                    Zhang</a>, Boyi Jiang, <strong>Yudong
                    Guo</strong>, <a href="http://staff.ustc.edu.cn/~lgliu/">Ligang Liu</a>, <a
                    href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) </em>, 2021
                  <br>
                  <a href="http://hy1995.top/StereoPIFuProject/">project page</a> /
                  <a href="https://arxiv.org/abs/2104.05289">paper</a> /
                  <a href="https://github.com/CrisHY1995/StereoPIFu_Code">code</a> 
                  <p>StereoPIFu integrates the geometric constraints of stereo vision with implicit representation to recover the 3D shape of the clothed human.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/Caricature.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2004.09190">
                    <papertitle>Landmark Detection and 3D Face Reconstruction for Caricature using a Nonlinear Parametric Model</papertitle>
                  </a>
                  <br>
                  <a href="https://github.com/RainbowRui">Hongrui Cai</a>, <strong>Yudong Guo</strong>, Zhuang Peng, <a
                    href="http://staff.ustc.edu.cn/~juyong/">Juyong
                    Zhang</a>
                  <br>
                  <em>Graphical Models </em>, 2021
                  <br>
                  <a href="https://arxiv.org/abs/2004.09190">paper</a> /
                  <a href="https://github.com/Juyong/CaricatureFace">code</a>
                  <p>We propose the first automatic method for landmark detection and 3D face reconstruction for caricature by a 3D approach.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/FacePS.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2003.12307">
                    <papertitle>Lightweight Photometric Stereo for Facial Details Recovery</papertitle>
                  </a>
                  <br>
                  Xueying Wang, <strong>Yudong Guo</strong>, <a href="http://www.bdeng.me/">Bailin Deng</a>, <a
                    href="http://staff.ustc.edu.cn/~juyong/">Juyong
                    Zhang</a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) </em>, 2020
                  <br>
                  <a href="https://arxiv.org/abs/2003.12307">paper</a> /
                  <a href="https://github.com/Juyong/FacePSNet">code</a>
                  <p>We present a framework to recover high-fidelity face shapes from one-to-three images captured under near lights.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;width:25%;vertical-align:middle">
                  <img src='images/CNNFace.png' style="width:200px;">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/1708.00980">
                    <papertitle>CNN-based Real-time Dense Face Reconstruction with Inverse-rendered Photo-realistic Face Images</papertitle>
                  </a>
                  <br>
                  <strong>Yudong Guo</strong>, <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>, <a
                    href="https://jianfei-cai.github.io/">Jianfei Cai</a>, Boyi Jiang, <a
                    href="https://personal.ntu.edu.sg/asjmzheng/">Jianmin Zheng</a>
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </em>, 2018
                  <br>
                  <a href="https://arxiv.org/abs/1708.00980">paper</a> /
                  <a href="data/3DFace.mp4">video</a> /
                  <a href="https://github.com/Juyong/3DFace">dataset</a>
                  <p>We present a novel face data generation method to train the 3DFaceNet for real-time dense face reconstruction from a monocular RGB video.</p>
                </td>
              </tr>

            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center">
                    <br>
                    Wonderful template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
